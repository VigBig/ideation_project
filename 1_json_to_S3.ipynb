{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n@Author: Vighnesh Harish Bilgi\\n@Date: 2022-11-25\\n@Last Modified by: Vighnesh Harish Bilgi\\n@Last Modified time: 2022-11-25\\n@Title : Ideation Project - 1. Transform JSON dataset to .csv file and upload it to an S3 Bucket\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "@Author: Vighnesh Harish Bilgi\n",
    "@Date: 2022-11-25\n",
    "@Last Modified by: Vighnesh Harish Bilgi\n",
    "@Last Modified time: 2022-11-25\n",
    "@Title : Ideation Project - 1. Transform JSON dataset to .csv file and upload it to an S3 Bucket\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = os.environ.get('test1_access_key')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = os.environ.get('test1_secret_access_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_json(file_name):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This function 'reads' a JSON file from path 'filename' and returns the JSON file as list of dictionaries.\n",
    "    Parameter:\n",
    "        string filename\n",
    "    Return:\n",
    "       list list_of_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_name,'r') as f:\n",
    "        list_of_dict = json.load(f)  \n",
    "    \n",
    "    return list_of_dict\n",
    "\n",
    "def remove_newline(list_of_dict):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        This function Removed newline '\\n' from values of 'body' key.\n",
    "    Parameter:\n",
    "       list list_of_dict\n",
    "    Return:\n",
    "       list list_of_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    for d in list_of_dict:\n",
    "        for k in d:\n",
    "            if k == 'body':\n",
    "                d[k] = d[k].replace(\"\\n\", \" \") \n",
    "    \n",
    "    return list_of_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_s3_client():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    # s3 =  boto3.resource('s3')\n",
    "    client = boto3.client(\"s3\")\n",
    "    return client\n",
    "\n",
    "\n",
    "def connect_to_s3_resource():\n",
    "    \"\"\"\n",
    "\n",
    "    Description:\n",
    "        To connect to AWS S3 service through an IAM user.\n",
    "    Parameter:\n",
    "        No parameters\n",
    "    Return:\n",
    "        ServiceResource s3\n",
    "    \"\"\"\n",
    "    s3 =  boto3.resource(service_name = 's3')\n",
    "    return s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transform JSON file to Pandas Dataframe and save it as .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing info about the dataframe:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   userId  100 non-null    int64 \n",
      " 1   id      100 non-null    int64 \n",
      " 2   title   100 non-null    object\n",
      " 3   body    100 non-null    object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 3.2+ KB\n",
      "None\n",
      "\n",
      " Printing top 10 rows about the dataframe:\n",
      "   userId  id                                              title  \\\n",
      "0       1   1  sunt aut facere repellat provident occaecati e...   \n",
      "1       1   2                                       qui est esse   \n",
      "2       1   3  ea molestias quasi exercitationem repellat qui...   \n",
      "3       1   4                               eum et est occaecati   \n",
      "4       1   5                                 nesciunt quas odio   \n",
      "5       1   6                 dolorem eum magni eos aperiam quia   \n",
      "6       1   7                               magnam facilis autem   \n",
      "7       1   8                           dolorem dolore est ipsam   \n",
      "8       1   9  nesciunt iure omnis dolorem tempora et accusan...   \n",
      "9       1  10                        optio molestias id quia eum   \n",
      "\n",
      "                                                body  \n",
      "0  quia et suscipit suscipit recusandae consequun...  \n",
      "1  est rerum tempore vitae sequi sint nihil repre...  \n",
      "2  et iusto sed quo iure voluptatem occaecati omn...  \n",
      "3  ullam et saepe reiciendis voluptatem adipisci ...  \n",
      "4  repudiandae veniam quaerat sunt sed alias aut ...  \n",
      "5  ut aspernatur corporis harum nihil quis provid...  \n",
      "6  dolore placeat quibusdam ea quo vitae magni qu...  \n",
      "7  dignissimos aperiam dolorem qui eum facilis qu...  \n",
      "8  consectetur animi nesciunt iure dolore enim qu...  \n",
      "9  quo et expedita modi cum officia vel magni dol...  \n"
     ]
    }
   ],
   "source": [
    "# Read JSON file and transform it into a list of dictionaries.\n",
    "file_name = \"posts.json\"\n",
    "list_of_dict = read_from_json(file_name)\n",
    "\n",
    "# Removing newline '\\n' from values of 'body' key.\n",
    "list_of_dict= remove_newline(list_of_dict)\n",
    "\n",
    "# Converting list_of_dict into dataframe\n",
    "df = pd.DataFrame(list_of_dict)\n",
    "print(\"Printing info about the dataframe:\")\n",
    "print(df.info())\n",
    "print(\"\\n Printing top 10 rows about the dataframe:\")\n",
    "print(df.head(10))\n",
    "\n",
    "df.to_csv('dataset.csv', index= False, header= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Send .csv file to an S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all bucket names to verify if - dataset-input-bucket is created:\n",
      "dataset-input-bucket\n",
      "redshift-twitter-input-bucket\n",
      "twitter-streaming-output-bucket\n"
     ]
    }
   ],
   "source": [
    "s3 = connect_to_s3_resource()\n",
    "client = connect_to_s3_client()\n",
    "\n",
    "# creating new bucket\n",
    "client.create_bucket(Bucket = 'dataset-input-bucket',ACL = 'public-read-write')\n",
    "print(\"Printing all bucket names to verify if - dataset-input-bucket is created:\")\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)\n",
    "\n",
    "# uploading csv file to the new bucket to be accessed by redshift \n",
    "client.upload_file(Filename = 'dataset.csv',Bucket = 'dataset-input-bucket', Key = 'data-source/dataset.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
